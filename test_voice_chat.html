<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Chat Test - RPS</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            margin-top: 0;
        }
        .controls {
            display: flex;
            gap: 10px;
            margin: 20px 0;
            flex-wrap: wrap;
            align-items: center;
        }
        button {
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            background: #007bff;
            color: white;
            cursor: pointer;
            font-size: 14px;
        }
        button:hover {
            background: #0056b3;
        }
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        button.danger {
            background: #dc3545;
        }
        button.danger:hover {
            background: #c82333;
        }
        button.recording {
            background: #dc3545;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
            background: #f0f0f0;
        }
        .status.connected { background: #d4edda; color: #155724; }
        .status.error { background: #f8d7da; color: #721c24; }
        .status.processing { background: #fff3cd; color: #856404; }
        .transcript {
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid #ddd;
            border-radius: 4px;
            padding: 10px;
            margin-top: 20px;
            background: #fafafa;
        }
        .message {
            margin: 10px 0;
            padding: 8px 12px;
            border-radius: 4px;
        }
        .message.user {
            background: #e3f2fd;
            margin-left: 20%;
            text-align: right;
        }
        .message.assistant {
            background: #f5f5f5;
            margin-right: 20%;
        }
        .config {
            margin: 20px 0;
        }
        .config input, .config select {
            width: 100%;
            padding: 8px;
            margin: 5px 0;
            border: 1px solid #ddd;
            border-radius: 4px;
            box-sizing: border-box;
        }
        .config label {
            display: block;
            margin-top: 10px;
            font-weight: bold;
            color: #555;
        }
        .audio-visualizer {
            height: 50px;
            background: #f0f0f0;
            border-radius: 4px;
            margin: 10px 0;
            display: flex;
            align-items: center;
            padding: 0 10px;
            gap: 2px;
        }
        .audio-bar {
            flex: 1;
            background: #007bff;
            height: 20px;
            border-radius: 2px;
            transition: height 0.1s ease;
            max-width: 30px;
        }
        .audio-bar.active {
            background: #28a745;
        }
        .text-input-container {
            display: flex;
            gap: 10px;
            margin: 20px 0;
        }
        .text-input-container input {
            flex: 1;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .info-panel {
            background: #f8f9fa;
            border-left: 4px solid #007bff;
            padding: 10px;
            margin: 10px 0;
            font-size: 14px;
        }
        .mic-selector {
            display: flex;
            gap: 10px;
            align-items: center;
            margin: 10px 0;
            padding: 10px;
            background: #f8f9fa;
            border-radius: 4px;
        }
        .mic-selector select {
            flex: 1;
            padding: 5px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .mic-status {
            display: inline-block;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: #dc3545;
            margin-left: 10px;
        }
        .mic-status.ready {
            background: #28a745;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Voice Chat Test</h1>
        
        <div class="config">
            <label>JWT Token:</label>
            <input type="text" id="jwtToken" placeholder="Paste your JWT token here">
            
            <label>Session ID:</label>
            <input type="text" id="sessionId" placeholder="Enter chat session ID">
        </div>

        <div class="mic-selector" id="micSelector" style="display: none;">
            <label style="margin: 0;">Microphone:</label>
            <select id="micSelect">
                <option value="">Default Microphone</option>
            </select>
            <span class="mic-status" id="micStatus"></span>
        </div>

        <div class="status" id="status">Disconnected</div>

        <div class="info-panel" id="infoPanel" style="display: none;">
            <strong>Audio Config:</strong> <span id="audioInfo">-</span><br>
            <strong>Voice:</strong> <span id="voiceInfo">-</span><br>
            <strong>Language:</strong> <span id="languageInfo">-</span><br>
            <strong>Microphone:</strong> <span id="micInfo">Not initialized</span>
        </div>

        <div class="controls">
            <button id="connectBtn" onclick="connect()">Connect</button>
            <button id="pushToTalkBtn" onmousedown="startRecording()" onmouseup="stopRecording()" onmouseleave="stopRecording()" disabled>
                üé§ Push to Talk
            </button>
            <button id="disconnectBtn" onclick="disconnect()" disabled>Disconnect</button>
            <span id="recordingInfo" style="margin-left: 10px; color: #666;"></span>
        </div>

        <div class="text-input-container">
            <input type="text" id="textInput" placeholder="Type a message..." disabled onkeypress="handleTextKeyPress(event)">
            <button id="sendTextBtn" onclick="sendTextMessage()" disabled>Send Text</button>
        </div>

        <div class="audio-visualizer" id="visualizer">
            <div class="audio-bar" id="bar1"></div>
            <div class="audio-bar" id="bar2"></div>
            <div class="audio-bar" id="bar3"></div>
            <div class="audio-bar" id="bar4"></div>
            <div class="audio-bar" id="bar5"></div>
            <div class="audio-bar" id="bar6"></div>
            <div class="audio-bar" id="bar7"></div>
            <div class="audio-bar" id="bar8"></div>
            <div class="audio-bar" id="bar9"></div>
            <div class="audio-bar" id="bar10"></div>
        </div>

        <div class="transcript" id="transcript">
            <div style="text-align: center; color: #999;">Transcript will appear here...</div>
        </div>
    </div>

    <script type="text/javascript">
        // No blob URLs needed - we'll use ScriptProcessorNode instead

        let ws = null;
        let audioContext = null;
        let audioStream = null;
        let analyser = null;
        let dataArray = null;
        let animationId = null;
        let isRecording = false;
        let audioConfig = {};
        let audioChunksSent = 0;
        let selectedMicId = null;
        let scriptProcessor = null;
        let recorder = null;
        let playbackContext = null;
        let audioQueue = [];
        let isPlaying = false;
        let currentSource = null;
        
        // New state for robust playback
        let audioBufferQueue = [];
        let audioProcessingInterval = null;
        let lastAudioTime = 0;

        async function connect() {
            const token = document.getElementById('jwtToken').value.trim();
            const sessionId = document.getElementById('sessionId').value.trim();

            if (!token || !sessionId) {
                alert('Please enter both JWT token and Session ID');
                return;
            }

            localStorage.setItem('rps_jwt_token', token);
            localStorage.setItem('rps_last_session', sessionId);

            const wsUrl = `ws://localhost:8000/api/voice/ws/${sessionId}?token=${token}`;
            ws = new WebSocket(wsUrl);

            ws.onopen = () => {
                console.log('WebSocket connected');
                updateStatus('Connected', 'connected');
                document.getElementById('connectBtn').disabled = true;
                document.getElementById('pushToTalkBtn').disabled = false;
                document.getElementById('textInput').disabled = false;
                document.getElementById('sendTextBtn').disabled = false;
                document.getElementById('disconnectBtn').disabled = false;
                document.getElementById('infoPanel').style.display = 'block';
            };

            ws.onmessage = async (event) => {
                const message = JSON.parse(event.data);
                handleMessage(message);
            };

            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                updateStatus('Connection error', 'error');
            };

            ws.onclose = (event) => {
                console.log('WebSocket closed:', event.code, event.reason);
                updateStatus(`Disconnected: ${event.reason || 'Connection closed'}`, 'error');
                resetUI();
            };
        }

        function handleMessage(message) {
            console.log('Received message:', message);

            switch (message.type) {
                case 'config':
                    audioConfig = message;
                    displayAudioConfig(message);
                    break;
                case 'audio':
                    playAudio(message.data);
                    break;
                case 'text':
                    addTranscript(message.data.text, message.data.role);
                    break;
                case 'interrupted':
                    interruptPlayback();
                    break;
                case 'turn_complete':
                    console.log('Model finished turn.');
                    break;
                case 'error':
                    updateStatus(`Error: ${message.error}`, 'error');
                    break;
            }
        }

        function _arrayBufferToBase64(buffer) {
            let binary = '';
            const bytes = new Uint8Array(buffer);
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }

        async function initializeAudio() {
            try {
                if (!audioContext || audioContext.state === 'closed') {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                }

                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const source = audioContext.createMediaStreamSource(stream);
                const processor = audioContext.createScriptProcessor(4096, 1, 1);

                processor.onaudioprocess = (e) => {
                    if (!isRecording) return;
                    
                    const inputData = e.inputBuffer.getChannelData(0);
                    const int16Data = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        int16Data[i] = Math.max(-32768, Math.min(32767, Math.floor(inputData[i] * 32768)));
                    }
                    
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        const base64Audio = _arrayBufferToBase64(int16Data.buffer);
                        const message = { mime_type: "audio/pcm", data: base64Audio };
                        ws.send(JSON.stringify(message));
                    }
                };

                source.connect(processor);
                processor.connect(audioContext.destination);

                recorder = { source, processor, stream };
                return true;
            } catch (error) {
                console.error('Error initializing audio:', error);
                updateStatus(`Mic error: ${error.message}`, 'error');
                return false;
            }
        }

        async function startRecording() {
            if (!recorder) {
                const success = await initializeAudio();
                if (!success) return;
            }
            isRecording = true;
            document.getElementById('pushToTalkBtn').classList.add('recording');
            document.getElementById('recordingInfo').textContent = 'Recording...';
        }

        function stopRecording() {
            isRecording = false;
            document.getElementById('pushToTalkBtn').classList.remove('recording');
            document.getElementById('recordingInfo').textContent = '';
        }

        function _base64ToArrayBuffer(base64) {
            const binaryString = atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        async function playAudio(base64Audio) {
            try {
                if (!playbackContext || playbackContext.state === 'closed') {
                    const sampleRate = audioConfig.output_sample_rate || 24000;
                    playbackContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate });
                }

                if (playbackContext.state === 'suspended') {
                    await playbackContext.resume();
                }

                const audioData = _base64ToArrayBuffer(base64Audio);
                audioQueue.push(audioData);

                if (!isPlaying) {
                    playNextInQueue();
                }
            } catch (error) {
                console.error('Error playing audio:', error);
            }
        }

        function playNextInQueue() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }
            isPlaying = true;

            const audioData = audioQueue.shift();
            const int16Array = new Int16Array(audioData);
            const float32Array = new Float32Array(int16Array.length);
            for (let i = 0; i < int16Array.length; i++) {
                float32Array[i] = int16Array[i] / 32768.0;
            }

            const audioBuffer = playbackContext.createBuffer(1, float32Array.length, playbackContext.sampleRate);
            audioBuffer.getChannelData(0).set(float32Array);

            const source = playbackContext.createBufferSource();
            source.buffer = audioBuffer;
            currentSource = source;
            source.connect(playbackContext.destination);

            source.onended = () => {
                currentSource = null;
                playNextInQueue();
            };
            source.start(0);
        }

        function interruptPlayback() {
            if (currentSource) {
                currentSource.onended = null;
                currentSource.stop();
                currentSource.disconnect();
                currentSource = null;
            }
            audioQueue = [];
            isPlaying = false;
        }

        function disconnect() {
            if (ws) {
                ws.close();
                ws = null;
            }
            stopRecording();
            interruptPlayback();
            if (recorder) {
                recorder.stream.getTracks().forEach(track => track.stop());
                recorder.source.disconnect();
                recorder.processor.disconnect();
                recorder = null;
            }
            if (audioContext && audioContext.state !== 'closed') audioContext.close();
            if (playbackContext && playbackContext.state !== 'closed') playbackContext.close();
            resetUI();
        }

        // Load saved preferences
        document.getElementById('jwtToken').value = localStorage.getItem('rps_jwt_token') || '';
        document.getElementById('sessionId').value = localStorage.getItem('rps_last_session') || '';
        selectedMicId = localStorage.getItem('rps_selected_mic') || null;

        // Enumerate microphones on page load
        async function enumerateMicrophones() {
            try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const micSelect = document.getElementById('micSelect');
                micSelect.innerHTML = '<option value="">Default Microphone</option>';
                
                const audioInputs = devices.filter(device => device.kind === 'audioinput');
                audioInputs.forEach((device, index) => {
                    const option = document.createElement('option');
                    option.value = device.deviceId;
                    option.text = device.label || `Microphone ${index + 1}`;
                    if (device.deviceId === selectedMicId) {
                        option.selected = true;
                    }
                    micSelect.appendChild(option);
                });
                
                if (audioInputs.length > 1) {
                    document.getElementById('micSelector').style.display = 'flex';
                }
            } catch (error) {
                console.error('Failed to enumerate devices:', error);
            }
        }

        // Initialize microphones list
        enumerateMicrophones();

        // Handle microphone selection change
        document.getElementById('micSelect').addEventListener('change', async (e) => {
            selectedMicId = e.target.value;
            localStorage.setItem('rps_selected_mic', selectedMicId);
            
            // If already connected, reinitialize microphone
            if (audioStream) {
                await initializeMicrophone();
            }
        });

        

        

        

        function displayAudioConfig(config) {
            document.getElementById('audioInfo').textContent = `${config.output_audio_format} @ ${config.output_sample_rate / 1000}kHz`;
            document.getElementById('voiceInfo').textContent = config.voice_name || 'default';
            document.getElementById('languageInfo').textContent = config.language || 'en';
        }

        async function sendTextMessage() {
            const textInput = document.getElementById('textInput');
            const text = textInput.value.trim();
            
            if (!text || !ws || ws.readyState !== WebSocket.OPEN) {
                return;
            }

            // Send text message using ADK format
            const message = {
                mime_type: "text/plain",
                data: btoa(unescape(encodeURIComponent(text)))  // Base64 encode the text
            };
            
            ws.send(JSON.stringify(message));
            
            // Add to transcript
            addTranscript(text, 'user');
            
            // Clear input
            textInput.value = '';
            
            // Update status
            document.getElementById('recordingInfo').textContent = 'Waiting for response...';
        }

        function handleTextKeyPress(event) {
            if (event.key === 'Enter') {
                sendTextMessage();
            }
        }

        function arrayBufferToBase64(buffer) {
            let binary = '';
            const bytes = new Uint8Array(buffer);
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return window.btoa(binary);
        }

        

        

        // Function to create WAV header for PCM data
        function createWavHeader(pcmLength, sampleRate = 16000, numChannels = 1, bitsPerSample = 16) {
            const header = new ArrayBuffer(44);
            const view = new DataView(header);
            const isFloat = bitsPerSample === 32;
            
            // "RIFF" chunk descriptor
            view.setUint32(0, 0x46464952, false); // "RIFF"
            view.setUint32(4, 36 + pcmLength, true); // file size - 8
            view.setUint32(8, 0x45564157, false); // "WAVE"
            
            // "fmt " sub-chunk
            view.setUint32(12, 0x20746d66, false); // "fmt "
            view.setUint32(16, 16, true); // subchunk size
            view.setUint16(20, isFloat ? 3 : 1, true); // audio format (1 = PCM, 3 = IEEE float)
            view.setUint16(22, numChannels, true); // number of channels
            view.setUint32(24, sampleRate, true); // sample rate
            view.setUint32(28, sampleRate * numChannels * bitsPerSample / 8, true); // byte rate
            view.setUint16(32, numChannels * bitsPerSample / 8, true); // block align
            view.setUint16(34, bitsPerSample, true); // bits per sample
            
            // "data" sub-chunk
            view.setUint32(36, 0x61746164, false); // "data"
            view.setUint32(40, pcmLength, true); // subchunk size
            
            return header;
        }

        

        

        function resetUI() {
            document.getElementById('connectBtn').disabled = false;
            document.getElementById('pushToTalkBtn').disabled = true;
            document.getElementById('textInput').disabled = true;
            document.getElementById('sendTextBtn').disabled = true;
            document.getElementById('disconnectBtn').disabled = true;
            document.getElementById('recordingInfo').textContent = '';
            document.getElementById('infoPanel').style.display = 'none';
            document.getElementById('micStatus').classList.remove('ready');
            document.getElementById('micInfo').textContent = 'Not initialized';
            
            // Reset audio bars
            for (let i = 1; i <= 10; i++) {
                document.getElementById(`bar${i}`).style.height = '5px';
                document.getElementById(`bar${i}`).classList.remove('active');
            }
        }

        function updateStatus(message, type = '') {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = 'status ' + type;
        }

        function addTranscript(text, role) {
            const transcriptEl = document.getElementById('transcript');
            
            // Clear initial message if present
            if (transcriptEl.querySelector('div[style*="text-align: center"]')) {
                transcriptEl.innerHTML = '';
            }

            const messageEl = document.createElement('div');
            messageEl.className = `message ${role}`;
            messageEl.textContent = text;
            transcriptEl.appendChild(messageEl);
            
            // Scroll to bottom
            transcriptEl.scrollTop = transcriptEl.scrollHeight;
        }

        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            if (ws) {
                ws.close();
            }
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
            }
        });
    </script>
</body>
</html>
